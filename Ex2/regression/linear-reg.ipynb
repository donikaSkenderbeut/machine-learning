{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement skopt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for skopt\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m space, gp_minimize\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt import space, gp_minimize\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/regression/Real estate train.csv')\n",
    "train.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg:\n",
    "    def fit(self, X, y):\n",
    "        X = np.insert(X, 0, np.ones(X.shape[0]), axis=1)\n",
    "        prod_1 = np.matmul(X.transpose(), X)\n",
    "        prod_2 = np.matmul(np.linalg.inv(prod_1), X.transpose())\n",
    "        self.beta = np.matmul(prod_2, y)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        tmp = np.insert(X_test, 0, np.ones(X_test.shape[0]), axis=1)\n",
    "        return np.matmul(tmp, self.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeReg(float):\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        identity_matrix = np.identity(X.shape[1])\n",
    "        prod_1 = np.matmul(X.transpose(), X)\n",
    "        prod_2 = self.l * identity_matrix\n",
    "        term_1 = np.add(prod_1, prod_2)\n",
    "        prod_3 = np.matmul(np.linalg.inv(term_1), X.transpose())\n",
    "\n",
    "        center_function = lambda x: x - x.mean()\n",
    "        y_centered = center_function(y)\n",
    "        self.y_mean = y.mean()\n",
    "\n",
    "        self.beta_rdige = np.matmul(prod_3, y_centered)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        inverse_center = lambda x: x + self.y_mean\n",
    "        return inverse_center(np.matmul(X_test, self.beta_rdige))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('target', axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "test = pd.read_csv('../data/regression/Real estate test.csv')\n",
    "test.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "X_test = test.drop('target', axis=1)\n",
    "y_test = test['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 square: 0.6974280661583799\n",
      "MAE:  4.432079085527506\n",
      "MSE:  34.706269250804866\n",
      "Sklearn's Linear Regression R2:  0.6974280661583799\n",
      "---------------------\n",
      "Manual Implementation of Linear Regression R2:  0.6974280661583802\n"
     ]
    }
   ],
   "source": [
    "sk_linreg = LinearRegression()\n",
    "sk_linreg.fit(X_train, y_train)\n",
    "y_pred = sk_linreg.predict(X_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred)\n",
    "# Printing the metrics\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)\n",
    "\n",
    "\n",
    "\n",
    "linreg = LinearReg()\n",
    "linreg.fit(X_train.values, y_train.values)\n",
    "y_pred_manual = linreg.predict(X_test.values)\n",
    "\n",
    "print(\"Sklearn's Linear Regression R2: \", r2_score(y_test, y_pred))\n",
    "print(\"---------------------\")\n",
    "print(\"Manual Implementation of Linear Regression R2: \", r2_score(y_test, y_pred_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 square: 0.6974280661583799\n",
      "MAE:  4.432079085527506\n",
      "MSE:  34.706269250804866\n",
      "Sklearn's Ridge R2:  0.6974584605943197\n",
      "---------------------\n",
      "Manual Implementation of Ridge Regression R2:  0.6974584605943213\n"
     ]
    }
   ],
   "source": [
    "sk_ridge = Ridge(alpha=1)\n",
    "sk_ridge.fit(X_train.values, y_train.values)\n",
    "y_pred_ridge = sk_ridge.predict(X_test.values)\n",
    "# Printing the metrics\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)\n",
    "\n",
    "\n",
    "ridge_manual = RidgeReg(l = 1)\n",
    "ridge_manual.fit(X_train.values, y_train.values)\n",
    "y_pred_ridge_manual = ridge_manual.predict(X_test.values)\n",
    "\n",
    "print(\"Sklearn's Ridge R2: \", r2_score(y_test, y_pred_ridge))\n",
    "print(\"---------------------\")\n",
    "print(\"Manual Implementation of Ridge Regression R2: \", r2_score(y_test, y_pred_ridge_manual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(par, x, y):\n",
    "    model = RidgeReg(l=par)\n",
    "    kf = KFold(n_splits=5)\n",
    "    accuracies = []\n",
    "    for idx in kf.split(X=x, y=y):\n",
    "        train_idx, test_idx = idx[0], idx[1]\n",
    "        xtrain = x[train_idx]\n",
    "        ytrain = y[train_idx]\n",
    "\n",
    "        xtest = x[test_idx]\n",
    "        ytest = y[test_idx]\n",
    "\n",
    "        model.fit(xtrain, ytrain)\n",
    "        preds = model.predict(xtest)\n",
    "        fold_acc = r2_score(ytest, preds)\n",
    "        accuracies.append(fold_acc)\n",
    "    \n",
    "    return -1.0 * np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 -0.6469289355500194\n"
     ]
    }
   ],
   "source": [
    "max=0\n",
    "best_param=0\n",
    "for i in range(10,2000):\n",
    "    res = optimize(par=i, x=X_train.values, y=y_train.values)\n",
    "    if (max > res):\n",
    "        max=res\n",
    "        best_param=i\n",
    "\n",
    "print(best_param, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1953115454.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [59]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def eval metrics (actual, pred):\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Prediction using test set \n",
    "y_pred = lin_reg.predict(x_test)\n",
    "mae=metrics.mean_absolute_error(y_test, y_pred)\n",
    "mse=metrics.mean_squared_error(y_test, y_pred)\n",
    "# Printing the metrics\n",
    "print('R2 square:',metrics.r2_score(y_test, y_pred))\n",
    "print('MAE: ', mae)\n",
    "print('MSE: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
